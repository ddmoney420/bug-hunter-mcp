---
type: code
status: in_progress
labels:
- workflow
- learning
- quiz
target_files:
- LESSONS.md
- CLAUDE.md
---
# Add Phase 3 Learn & Retain workflow with quiz system

## Background

Bug hunting should be educational, not just mechanical. Each bug is a real-world CS case study. By adding a mandatory quiz phase after each fix, we ensure:

1. Deep understanding of the root cause
2. Retention of language/framework concepts
3. Pattern recognition across codebases
4. Mastery-based progression (can't proceed until you understand)

This transforms bug-hunter-mcp from a fixing tool into a **hypercharged CS professor** driven by real-world examples.

## The Learning Loop

```
Bug Found → Research → Fix → Debrief → Quiz → Pass? → Next Bug
                                          ↓
                                         Fail
                                          ↓
                                    Review & Retake
```

## Phase 3: Learn & Retain

After a fix is submitted (PR opened or merged):

### 1. Debrief
Document in LESSONS.md:
- **Root cause**: What was actually broken and why
- **CS concepts**: Language features, patterns, architecture involved
- **The fix**: Why this solution works
- **Alternatives**: Other approaches considered and why rejected
- **Gotchas**: Tricky parts, edge cases, things that surprised you

### 2. Quiz (1-5 multiple choice questions)
Questions should test:
- Understanding of the root cause (not just "what file did you change")
- Language/runtime concepts (Zig optionals, JS event loop, Go interfaces, etc.)
- Debugging methodology (how did we find it?)
- Architecture awareness (why was the code structured this way?)
- General CS principles when applicable

Quiz format:
```
Q1: [Question about root cause]
A) ...
B) ... ✓
C) ...
D) ...
```

### 3. Gate Check
- **Pass (≥80%)**: Log the lesson, update stats, proceed to next bug
- **Fail**: Review incorrect answers, explain concepts, retake quiz
- **No new bugs until quiz passed**

## Acceptance Criteria

- [x] Add Phase 3 section to LESSONS.md workflow
- [x] Define quiz format and passing threshold (≥80%)
- [x] Add "Lessons by Project" template with debrief sections
- [x] Add quiz tracking to Stats section (quizzes taken, pass rate)
- [x] Update CLAUDE.md to reference the learning workflow
- [x] Add example quiz from Bun #19952 console.trace fix
- [x] Document the gate check rule: no new bugs until quiz passed

## Example Quiz (Bun #19952)

```markdown
### Quiz: Bun console.trace() stderr fix

**Q1: Why did console.trace() output to stdout instead of stderr?**
A) The writeTrace() function had a typo
B) The writer selection checked log LEVEL but not message TYPE
C) stderr was locked by another process
D) Bun intentionally differs from Node.js

**Q2: In Zig, what does the `orelse` keyword do?**
A) Performs a logical OR operation
B) Unwraps an optional value, providing a fallback if null
C) Handles exceptions like try/catch
D) Continues to the next loop iteration

**Q3: According to WHATWG Console Standard, where should trace output go?**
A) stdout (standard output)
B) stderr (standard error)
C) A separate trace log file
D) Depends on the runtime implementation

**Q4: What pattern should you look for when output goes to the wrong stream?**
A) Check if the file descriptor is correct
B) Look for conditions that select between stdout/stderr writers
C) Verify the terminal supports the output
D) Check network connectivity

Answers: B, B, B, B
```

## Notes

- Quizzes should be genuinely educational, not gotchas
- Wrong answers should be plausible (test understanding, not trick)
- Keep questions focused on transferable knowledge
- Track weak areas over time for targeted review